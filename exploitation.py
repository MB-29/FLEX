import numpy as np
import importlib
import torch
import matplotlib.pyplot as plt


def task_cost(U, x0, dynamics, dt, T, step_cost, gradient_step=None, plot=None):
    value = 0.0
    x_t = torch.tensor(x0, dtype=torch.float)
    for t in range(T):
        u_t = U[t, :]
        # u_t = torch.clip(u_t, -gamma, gamma)
        # print(f'xt {x_t}')
        value += step_cost(x_t, u_t)
        # print(f'gradient_step {gradient_step}, t={t}, value {value}')
        # print(f'dt = {dt}')
        x_t_ = x_t + dt*dynamics(x_t, u_t)
        x_t = x_t_
        if plot is not None:
            plot(x_t.detach().numpy(), u_t.detach().numpy())
            text = f'step {gradient_step}, t={t}, x={x_t}'
            plt.title(text)
            plt.pause(0.1)
            plt.close()
    return value

def plan(model, x0, step_cost, dt, T, gamma, m, n_gradient, lr=0.02):
    U = torch.randn(T, m, requires_grad=True)
    optimizer = torch.optim.Adam([U], lr)
    loss_values = np.zeros(n_gradient)
    for gradient_step in range(n_gradient):
        V = torch.clip(U, -gamma, gamma)
        loss = task_cost(V, x0, model, dt, T, step_cost, gradient_step)
        loss_values[gradient_step] = loss
        # print(f'loss = {loss}')

        optimizer.zero_grad() ; loss.backward() ; optimizer.step()
    return U, loss_values

def exploitation(environment, model, T, n_gradient=500):
    U, loss_values = plan(
        model,
        environment.x0,
        environment.step_cost,
        environment.dt,
        T,
        environment.gamma,
        environment.m,
        n_gradient
        )
    cost = task_cost(
        U,
        environment.x0,
        environment.dynamics,
        environment.dt,
        T,
        environment.step_cost
        )
    return cost, loss_values
    # model = environment.d_dynamics
    # U, loss_values = plan(model)
    # final_cost = task_cost(U, environment.dynamics)
    # print(f'final cost: {final_cost}')

    # plt.plot(loss_values) ; plt.show()
