import torch
import torch.nn as nn
from tqdm import tqdm

from mpc import mpc
from mpc.mpc import QuadCost, GradMethods

import numpy as np
import matplotlib.pyplot as plt

from environments import get_environment


class TransitionModel(nn.Module):
    def __init__(self, model_dynamics, environment, dt):
        self.dynamics = model_dynamics
        self.environment = environment
        self.dt = dt
        super().__init__()
    
    def forward(self, obs, u):
        x = self.environment.get_state(obs)
        z = torch.cat((x, u), dim=1)
        d_x = self.dynamics(z)
        x_ = x + self.dt*d_x
        obs_ = self.environment.observe(x_)
        return obs_


def exploit(environment, model_dynamics, dt, T, H, plot=False):
    dynamics = environment.d_dynamics


    dx = TransitionModel(model_dynamics, environment, dt)
    dx_star = TransitionModel(dynamics, environment, dt)

    m = environment.m
    n_batch = 1

    # obs = torch.tensor([cphi0, sphi0, 0.0], dtype=torch.float).unsqueeze(0)
    obs = environment.observe(torch.tensor(environment.x0, dtype=torch.float).unsqueeze(0))
    u_init = None

    # The cost terms for the swingup task can be alternatively obtained
    # for this pendulum environment with:
    # q, p = dx.get_true_obj()

    goal_weights, goal_state = environment.goal_weights, environment.goal_state
    R = environment.R
    q = torch.cat((
        goal_weights,
        R*torch.ones(m)
    ))
    px = -torch.sqrt(goal_weights)*goal_state
    p = torch.cat((px, torch.zeros(m)))
    Q = torch.diag(q).unsqueeze(0).unsqueeze(0).repeat(
        H, n_batch, 1, 1
    )
    p = p.unsqueeze(0).repeat(H, n_batch, 1)


    cost_values = np.zeros(T)
    for t in range(T):
        nominal_states, nominal_actions, nominal_objs = mpc.MPC(
            3, 1, H,
            u_init=u_init,
            u_lower=-environment.gamma, u_upper=environment.gamma,
            lqr_iter=5,
            verbose=0,
            exit_unconverged=False,
            detach_unconverged=False,
            # linesearch_decay=dx.linesearch_decay,
            # max_linesearch_iter=dx.max_linesearch_iter,
            grad_method=GradMethods.AUTO_DIFF,
            # eps=1e-2,
        )(obs, QuadCost(Q, p), dx)

        next_action = nominal_actions[0]
        u_init = torch.cat(
            (nominal_actions[1:], torch.zeros(1, n_batch, m)), dim=0)
        u_init[-2] = u_init[-3]

        z_tilde = torch.cat((obs-goal_state, next_action), dim=1)

        C = torch.diag(torch.tensor([100., .1, .1, .001], dtype=torch.float))
        cost = torch.sum(z_tilde*(C@z_tilde.T).T, axis=1)
        cost_values[t] = cost.detach()

        obs = dx_star(obs, next_action)

        if not plot:
            continue 
            # print(f'obs = {obs.shape}')
        state = environment.get_state(obs[0].unsqueeze(0))
        # print(f'state = {state}')
        environment.plot_pendulum(
            state.squeeze().detach().numpy(),
            next_action[0].detach().numpy(),
            0)
        # axs[i].get_xaxis().set_visible(False)
        # axs[i].get_yaxis().set_visible(False)
        plt.pause(0.1)
        plt.close()

    return cost_values

# plot=False
# plot=True

# ENVIRONMENT_NAME = 'gym_pendulum'
# ENVIRONMENT_PATH = f'environments.{ENVIRONMENT_NAME}'
# Environment = get_environment(ENVIRONMENT_NAME)

# T, H = 100, 20
# dt = 80e-3


# environment = Environment(dt)
# model = torch.load('output/models/pendulum/D-optimal_sample-1_episode-14.dat')
# model_dynamics = environment.d_dynamics
# # model_dynamics = model.forward


# cost_values = exploit(environment, model_dynamics, dt, T, H, plot)


# plt.subplot(211)
# plt.plot(cost_values.cumsum())
# plt.subplot(212)
# plt.plot(cost_values)
# plt.show()
